{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.post2+cxx11.abi\n",
      "2.1.30.post0 \n",
      "[0]: _DeviceProperties(name='Intel(R) Arc(TM) A770 Graphics', platform_name='Intel(R) Level-Zero', dev_type='gpu', driver_version='1.3.29803', has_fp64=0, total_memory=15930MB, max_compute_units=512, gpu_eu_count=512)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import schedulefree\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from replay_loading import enum_replay_folder, files_to_strokes, sample_stroke\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "print(torch.__version__)\n",
    "print(ipex.__version__)\n",
    "[print(f'[{i}]: {torch.xpu.get_device_properties(i)}') for i in range(torch.xpu.device_count())]\n",
    "\n",
    "device = torch.device(\"xpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:24<00:00, 12.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1930021"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_fns = list(itertools.islice(enum_replay_folder(\"H:/osu!/Data/r/\"), 300))\n",
    "strokes_subset = list(files_to_strokes(tqdm(replay_fns), min_length=50))\n",
    "sum((len(s[0]) for s in strokes_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        strokes,\n",
    "        common_transforms=None,\n",
    "        input_transforms=None,\n",
    "        target_transforms=None,\n",
    "        common_split_transforms=None,\n",
    "    ):\n",
    "        self.strokes = strokes\n",
    "        self.common_transforms = common_transforms\n",
    "        self.input_transforms = input_transforms\n",
    "        self.target_transforms = target_transforms\n",
    "        self.common_split_transforms = common_split_transforms\n",
    "        self.wrand_sampler = WeightedRandomSampler([len(s[0]) for s in strokes], len(strokes), replacement=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strokes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.strokes[idx]\n",
    "\n",
    "        for transform in self.common_transforms:\n",
    "            sample = transform(sample)\n",
    "        target = sample.copy()\n",
    "\n",
    "        for transform in self.input_transforms:\n",
    "            sample = transform(sample)\n",
    "\n",
    "        for transform in self.target_transforms:\n",
    "            target = transform(target)\n",
    "\n",
    "        if self.common_split_transforms:\n",
    "            for transform in self.common_split_transforms:\n",
    "                sample = transform(sample)\n",
    "                target = transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "class StrokeResample:\n",
    "    def __init__(self, rate_dist=st.uniform(30, 250), max_length=2048):\n",
    "        self.rate_dist = rate_dist\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        timings, positions = sample\n",
    "        rate = self.rate_dist.rvs(1).item()\n",
    "        offset = np.random.uniform(0, 1 / rate)\n",
    "        return sample_stroke(timings, positions, rate, offset, max_length=self.max_length)\n",
    "\n",
    "\n",
    "class ScaleRotateFlip:\n",
    "    def __init__(self, scale_dist=st.uniform(0.5, 1.5)):\n",
    "        self.scale_dist = scale_dist\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scale = self.scale_dist.rvs(1).item()\n",
    "        sample = sample * scale\n",
    "        angle = random.uniform(-np.pi, np.pi)\n",
    "        flip = random.choice([1, -1])\n",
    "        rotation_matrix = np.array([[np.cos(angle), -flip * np.sin(angle)], [flip * np.sin(angle), np.cos(angle)]])\n",
    "        sample = sample @ rotation_matrix\n",
    "        return sample\n",
    "\n",
    "\n",
    "class LeftPad:\n",
    "    def __init__(self, target_length=2048):\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        padding_width = self.target_length - len(sample)\n",
    "        return np.pad(sample, ((padding_width, 0), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, std_dist=st.expon(scale=0.5)):\n",
    "        self.std_dist = std_dist\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        std = self.std_dist.rvs(1).item()\n",
    "        noise = np.random.normal(0, std, sample.shape)\n",
    "        return sample + noise\n",
    "\n",
    "\n",
    "class SmoothWithGaussian:\n",
    "    def __init__(self, sigma_dist=st.expon(scale=0.5)):\n",
    "        self.sigma_dist = sigma_dist\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sigma = self.sigma_dist.rvs(1).item()\n",
    "        return gaussian_filter1d(sample, sigma, axis=0)\n",
    "\n",
    "\n",
    "class StrokeDiff:\n",
    "    def __call__(self, sample):\n",
    "        return np.diff(sample, axis=0)\n",
    "\n",
    "\n",
    "class StrokeToTensor:\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample).float()\n",
    "\n",
    "\n",
    "def collate_simple_stack(batch):\n",
    "    return torch.stack([stroke for stroke, _ in batch]).mT, torch.stack([target for _, target in batch]).mT\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "seq_len = 4096\n",
    "\n",
    "transforms = {\n",
    "    \"common_transforms\": [\n",
    "        StrokeResample(max_length=seq_len),\n",
    "        ScaleRotateFlip(),\n",
    "        LeftPad(target_length=seq_len),\n",
    "    ],\n",
    "    \"input_transforms\": [\n",
    "        AddGaussianNoise(),\n",
    "    ],\n",
    "    \"target_transforms\": [\n",
    "        SmoothWithGaussian(),\n",
    "    ],\n",
    "    \"common_split_transforms\": [\n",
    "        StrokeDiff(),\n",
    "        StrokeToTensor(),\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "ds_small = StrokeDataset(strokes_subset, **transforms)\n",
    "ds_small_loader = DataLoader(\n",
    "    ds_small, batch_size=batch_size, sampler=ds_small.wrand_sampler, collate_fn=collate_simple_stack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2, 4095])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds_small_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = pickle.load(open(\"all_strokes.pkl\", \"rb\"))\n",
    "\n",
    "ds_full = StrokeDataset(all_strokes, **transforms)\n",
    "ds_full_loader = DataLoader(ds_full, batch_size=batch_size, sampler=ds_full.wrand_sampler, collate_fn=collate_simple_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1])\n",
      "Input channels: tensor([ 2, 10, 18, 26, 34, 38, 42, 46, 50, 52, 54, 56, 58])\n",
      "Channels: tensor([ 8,  8,  8,  8,  4,  4,  4,  4,  2,  2,  2,  2, 10])\n",
      "Dilations: None\n",
      "Pads: tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0])\n",
      "Total padding: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 5, 464])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "16412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestNet(torch.jit.ScriptModule):\n",
    "    def __init__(self, kernels=[5] * 12, channels=[8] * 4 + [4] * 4 + [2] * 4, dilations=None, out_steps=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernels = torch.tensor(kernels + [1])\n",
    "        self.out_steps = out_steps\n",
    "        self.channels = torch.tensor(channels + [2 * out_steps])\n",
    "        self.in_channels = torch.tensor([2] + channels).cumsum(dim=0)\n",
    "        self.total_channels = self.in_channels[-1].item() + 2\n",
    "        self.dilations = torch.tensor(dilations + [1]) if dilations is not None else None\n",
    "        self.pads = (self.kernels - 1) * (self.dilations if self.dilations is not None else 1)\n",
    "        self.pad_total = self.pads.sum().item()\n",
    "        self.pad_max = self.pads.max().item()\n",
    "        self.ar_len = 5\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.in_channels[i].item(),\n",
    "                    out_channels=self.channels[i].item() * 2,\n",
    "                    kernel_size=self.kernels[i].item(),\n",
    "                    dilation=self.dilations[i].item() if self.dilations is not None else 1,\n",
    "                )\n",
    "                for i in range(len(self.kernels))\n",
    "            ]\n",
    "        )\n",
    "        self.n_layers = len(self.convs)\n",
    "\n",
    "        print(f\"Kernels: {self.kernels}\")\n",
    "        print(f\"Input channels: {self.in_channels}\")\n",
    "        print(f\"Channels: {self.channels}\")\n",
    "        print(f\"Dilations: {self.dilations}\")\n",
    "        print(f\"Pads: {self.pads}\")\n",
    "        print(f\"Total padding: {self.pad_total}\")\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        # input is (batch, channels, seq_len)\n",
    "        B, _, L = x.shape\n",
    "        curr_window = torch.tensor(x.shape[-1])\n",
    "        acts = [x]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = torch.cat([act[..., -curr_window:] for act in acts], dim=1)\n",
    "            x = conv(x)\n",
    "            x = F.glu(x, dim=1)\n",
    "            curr_window -= self.pads[i]\n",
    "            acts.append(x)\n",
    "        return x.view(B, 2, self.out_steps, L-self.pad_total) # (batch, 2, out_steps, seq_len-pad)\n",
    "        # return x.transpose(1, 2).view(B, L-self.pad_total, 2, self.out_steps)\n",
    "\n",
    "model = TestNet()\n",
    "\n",
    "with torch.no_grad():\n",
    "    display(model(torch.rand(8, 2, 512)).shape)\n",
    "\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_loss_weights = 1 / np.arange(2, 7)\n",
    "\n",
    "def multistep_loss(input, preds):\n",
    "    in_L = input.shape[-1]\n",
    "    out_L = preds.shape[-1]\n",
    "    return torch.stack(\n",
    "        [\n",
    "            lw\n",
    "            * F.huber_loss(\n",
    "                # input (batch, 2, seq_len)\n",
    "                # preds (batch, 2, out_steps, seq_len-pad)\n",
    "                input[..., 1 + in_L - out_L + step : in_L ],\n",
    "                preds[..., step,                   : out_L - step - 1],\n",
    "            )\n",
    "            for step, lw in enumerate(step_loss_weights)\n",
    "        ]\n",
    "    ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [04:55<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.840942622731425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get benchmark loss on one epoch\n",
    "\n",
    "class CopyLastBenchmark(torch.jit.ScriptModule):\n",
    "    def __init__(self, out_steps=5):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        return x.unsqueeze(2).expand(-1, -1, self.out_steps, -1)\n",
    "\n",
    "benchmark_model = CopyLastBenchmark()\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for batch_input, batch_target in tqdm(ds_full_loader):\n",
    "        # batch = batch.mT\n",
    "        losses.append(multistep_loss(batch_target, benchmark_model(batch_input)).item())\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 5, 5, 5, 3, 3, 3, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 17, 20, 23, 25, 27, 29])\n",
      "Channels: tensor([ 4,  4,  4,  3,  3,  3,  2,  2,  2, 10])\n",
      "Dilations: tensor([ 1,  2,  8, 12, 16, 12,  8,  2,  1,  1])\n",
      "Pads: tensor([ 6, 12, 48, 48, 64, 48, 16,  4,  2,  0])\n",
      "Total padding: 248\n",
      "4092\n"
     ]
    }
   ],
   "source": [
    "dilated_params = {\n",
    "    \"kernels\": [7, 7, 7, 5, 5, 5, 3, 3, 3],\n",
    "    \"channels\": [4, 4, 4, 3, 3, 3, 2, 2, 2],\n",
    "    \"dilations\": [1, 2, 8, 12, 16, 12, 8, 2, 1],\n",
    "}\n",
    "model = TestNet(**dilated_params)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 5, 5, 5, 3, 3, 3, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 17, 20, 23, 25, 27, 29])\n",
      "Channels: tensor([ 4,  4,  4,  3,  3,  3,  2,  2,  2, 10])\n",
      "Dilations: tensor([ 1,  2,  8, 12, 16, 12,  8,  2,  1,  1])\n",
      "Pads: tensor([ 6, 12, 48, 48, 64, 48, 16,  4,  2,  0])\n",
      "Total padding: 248\n",
      "4092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TestNet4(\n",
       "   (convs): RecursiveScriptModule(\n",
       "     original_name=ModuleList\n",
       "     (0): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (1): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (2): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (3): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (4): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (5): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (6): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (7): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (8): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (9): RecursiveScriptModule(original_name=Conv1d)\n",
       "   )\n",
       " ),\n",
       " AdamWScheduleFree (\n",
       " Parameter Group 0\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     foreach: True\n",
       "     k: 0\n",
       "     lr: 0.0025\n",
       "     lr_max: -1.0\n",
       "     r: 0.0\n",
       "     train_mode: True\n",
       "     warmup_steps: 0\n",
       "     weight_decay: 0.001\n",
       "     weight_lr_power: 2.0\n",
       "     weight_sum: 0.0\n",
       " ))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.xpu.empty_cache()\n",
    "model.to(device)\n",
    "unpad = model.pad_total + 1\n",
    "optimizer = schedulefree.AdamWScheduleFree(model.parameters(), lr=0.0025, weight_decay=0.001)\n",
    "ipex.optimize(model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 47/874 [00:20<05:58,  2.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):  \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     epoch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_target\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_full_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# batch = batch.mT.to(device) # (batch, 2, seq_len)\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mStrokeDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     21\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrokes[idx]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommon_transforms:\n\u001b[1;32m---> 24\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m target \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_transforms:\n",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m, in \u001b[0;36mStrokeResample.__call__\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m     48\u001b[0m rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_dist\u001b[38;5;241m.\u001b[39mrvs(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     49\u001b[0m offset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m rate)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msample_stroke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\Projects\\Neuropolator\\notebooks\\replay_loading.py:169\u001b[0m, in \u001b[0;36msample_stroke\u001b[1;34m(timings, positions, rate, offset, max_length)\u001b[0m\n\u001b[0;32m    167\u001b[0m knot_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(positions, [t_ind\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, t_ind\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, t_ind, t_ind\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    168\u001b[0m knot_weights \u001b[38;5;241m=\u001b[39m cubic_barry_goldman_weights(knots_interp, t_interp)\n\u001b[1;32m--> 169\u001b[0m interp_positions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknot_positions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mknot_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m interp_positions\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2172\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[0;32m   2104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \n\u001b[0;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2173\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m   2177\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2179\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "losses = []\n",
    "losses_verbose = []\n",
    "\n",
    "model.train()\n",
    "optimizer.train()\n",
    "for epoch in range(n_epochs):  # number of epochs\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch_input, batch_target in tqdm(ds_full_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # batch = batch.mT.to(device) # (batch, 2, seq_len)\n",
    "        batch = batch_input.to(device)\n",
    "        outputs = model(batch)\n",
    "        loss = multistep_loss(batch_target.to(device), outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_verbose.append(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "\n",
    "model.eval()\n",
    "optimizer.eval()\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(losses_verbose).flatten())\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "torch.save(model.state_dict(), \"./tmpmodel4.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./tmpmodel4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 5, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    display(model(torch.rand(8, 2, 249)).shape)\n",
    "    # display(model(torch.rand(8, 249, 2)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abstract\\mambaforge\\envs\\intel_dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527: UserWarning: The grad mode is detected as torch.no_grad() is NOT enabled. In this mode on XPU, please expect NO graph and fusion optimization will be applied. \n",
      " (Triggered internally at C:/jenkins/workspace/IPEX-GPU-ARC770-Windows-Build/frameworks.ai.pytorch.ipex-gpu/csrc/gpu/jit/fusion_pass.cpp:829.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 2, 249)\n",
    "torch.onnx.export(model, x, \"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
