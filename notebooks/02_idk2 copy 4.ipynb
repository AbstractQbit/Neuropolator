{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from replay_loading import enum_replay_folder, files_to_strokes, sample_stroke\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:17<00:00, 17.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1940603"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_fns = list(itertools.islice(enum_replay_folder(\"H:/osu!/Data/r/\"), 300))\n",
    "strokes_subset = list(files_to_strokes(tqdm(replay_fns), min_length=50))\n",
    "sum((len(s[0]) for s in strokes_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_replays = list(enum_replay_folder(\"H:/osu!/Data/r/\"))\n",
    "# all_strokes = list(files_to_strokes(tqdm(all_replays), min_length=50))\n",
    "# pickle.dump(all_strokes, open(\"all_strokes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = pickle.load(open(\"all_strokes.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, strokes, transforms=None):\n",
    "        self.strokes = strokes\n",
    "        self.transforms = transforms\n",
    "        self.wrand_sampler = WeightedRandomSampler([len(s[0]) for s in strokes], len(strokes), replacement=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strokes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.strokes[idx]\n",
    "        \n",
    "        # Apply the transformations if any\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                sample = transform(sample)\n",
    "            return sample\n",
    "        else:\n",
    "            return sample[1]\n",
    "\n",
    "\n",
    "class StrokeResample:\n",
    "    def __init__(self, rate_range=(30, 250), max_length=2048):\n",
    "        self.rate_range = rate_range\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        timings, positions = sample\n",
    "        rate = np.random.uniform(*self.rate_range)\n",
    "        offset = np.random.uniform(0, 1/rate)\n",
    "        return sample_stroke(timings, positions, rate, offset, max_length=self.max_length)\n",
    "\n",
    "\n",
    "class StrokeDiff:\n",
    "    def __call__(self, sample):\n",
    "        return np.diff(sample, axis=0)\n",
    "\n",
    "\n",
    "class ScaleRotateFlip:\n",
    "    def __init__(self, scale_range=(0.5, 1.5)):\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scale = random.uniform(*self.scale_range)\n",
    "        sample = sample * scale\n",
    "        angle = random.uniform(-np.pi, np.pi)\n",
    "        flip = random.choice([1, -1])\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(angle), -flip * np.sin(angle)],\n",
    "            [flip * np.sin(angle), np.cos(angle)]])\n",
    "        sample = sample @ rotation_matrix\n",
    "        return sample\n",
    "\n",
    "\n",
    "class StrokeToTensor:\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample).float()\n",
    "\n",
    "\n",
    "def collate_pad_beginning_zeroes(batch):\n",
    "    max_len = max([len(stroke) for stroke in batch])\n",
    "    padded_batch = [F.pad(stroke, (0, 0, max_len - len(stroke), 0)) for stroke in batch]\n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    StrokeResample(max_length=4096),\n",
    "    StrokeDiff(),\n",
    "    ScaleRotateFlip(),\n",
    "    StrokeToTensor(),\n",
    "]\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "ds_small = StrokeDataset(strokes_subset, transforms=transforms)\n",
    "ds_small_loader = DataLoader(ds_small, batch_size=batch_size, sampler=ds_small.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)\n",
    "\n",
    "ds_full = StrokeDataset(all_strokes, transforms=transforms)\n",
    "ds_full_loader = DataLoader(ds_full, batch_size=batch_size, sampler=ds_full.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1]) torch.Size([13])\n",
      "Input channels: tensor([ 2, 10, 18, 26, 34, 38, 42, 46, 50, 52, 54, 56, 58]) torch.Size([13])\n",
      "Channels: tensor([8, 8, 8, 8, 4, 4, 4, 4, 2, 2, 2, 2, 2]) torch.Size([13])\n",
      "Dilations: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) torch.Size([13])\n",
      "Pads: tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0]) torch.Size([13])\n",
      "Total padding: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15468"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestNet3(nn.Module):\n",
    "    def __init__(\n",
    "        self, kernels=[5] * 12, channels=[8] * 4 + [4] * 4 + [2] * 4, dilations=[1] * 12\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernels = torch.tensor(kernels + [1])\n",
    "        self.channels = torch.tensor(channels + [2])\n",
    "        self.in_channels = torch.tensor([2] + channels).cumsum(dim=0)\n",
    "        self.total_channels = self.in_channels[-1].item() + 2\n",
    "        self.dilations = torch.tensor(dilations + [1])\n",
    "        # self.pads = [\n",
    "        #     ((kernel - 1) * dilation).item()\n",
    "        #     for kernel, dilation in zip(self.kernels, self.dilations)\n",
    "        # ]\n",
    "        # self.pad_total = sum(self.pads)#.item()\n",
    "        self.pads = (self.kernels - 1) * self.dilations\n",
    "        self.pad_total = self.pads.sum().item()\n",
    "        self.ar_len = None\n",
    "\n",
    "        print(f\"Kernels: {self.kernels} {self.kernels.shape}\")\n",
    "        print(f\"Input channels: {self.in_channels} {self.in_channels.shape}\")\n",
    "        print(f\"Channels: {self.channels} {self.channels.shape}\")\n",
    "        print(f\"Dilations: {self.dilations} {self.dilations.shape}\")\n",
    "        print(f\"Pads: {self.pads} {self.pads.shape}\")\n",
    "        print(f\"Total padding: {self.pad_total}\")\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.in_channels[i].item(),\n",
    "                    out_channels=self.channels[i].item() * 2,\n",
    "                    kernel_size=self.kernels[i].item(),\n",
    "                    dilation=self.dilations[i].item(),\n",
    "                )\n",
    "                for i in range(len(self.kernels))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input is (batch, seq_len, 2)\n",
    "        # x = x.mT  # (batch, 2, seq_len)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[-1]\n",
    "        if self.ar_len is None:\n",
    "            acts = torch.empty(\n",
    "                batch_size, self.total_channels, seq_len, device=x.device\n",
    "            )\n",
    "            acts[..., :2, :] = x\n",
    "            curr_window = seq_len\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                channel_start = self.in_channels[i].item()\n",
    "                channel_end = channel_start + self.channels[i].item()\n",
    "                x = acts[..., :channel_start, -curr_window:]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=-2)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[\n",
    "                    ...,\n",
    "                    channel_start:channel_end,\n",
    "                    -curr_window:,\n",
    "                ] = x\n",
    "            return acts[..., -2:, -curr_window:]  # .mT\n",
    "        else:\n",
    "            acts = torch.empty(\n",
    "                batch_size,\n",
    "                self.total_channels,\n",
    "                seq_len + self.ar_len - 1,\n",
    "                device=x.device,\n",
    "            )\n",
    "            acts[..., :2, :seq_len] = x\n",
    "            # first pass\n",
    "            curr_window = seq_len\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                channel_start = self.in_channels[i]\n",
    "                channel_end = channel_start + self.channels[i]\n",
    "                x = acts[..., :channel_start, seq_len - curr_window : seq_len]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=-2)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[\n",
    "                    ...,\n",
    "                    channel_start:channel_end,\n",
    "                    seq_len - curr_window : seq_len,\n",
    "                ] = x\n",
    "            # later autoregressive passes\n",
    "            for ar_step in range(1, self.ar_len):\n",
    "                step_col = ar_step - self.ar_len\n",
    "                acts[..., :2, step_col] = acts[..., -2:, step_col - 1]\n",
    "                for i, conv in enumerate(self.convs):\n",
    "                    channel_start = self.in_channels[i]\n",
    "                    channel_end = channel_start + self.channels[i]\n",
    "                    x = acts[\n",
    "                        ...,\n",
    "                        :channel_start,\n",
    "                        step_col - self.pads[i] - 1 : step_col,\n",
    "                    ]\n",
    "                    x = conv(x)\n",
    "                    x = F.glu(x, dim=-2)\n",
    "                    acts[\n",
    "                        ...,\n",
    "                        channel_start:channel_end,\n",
    "                        step_col : step_col + 1,\n",
    "                    ] = x\n",
    "            return acts[..., -2:, -self.ar_len :]  # .mT\n",
    "\n",
    "\n",
    "sum(p.numel() for p in TestNet3().parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([8, 6, 4, 3, 2, 1]) torch.Size([6])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12]) torch.Size([6])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2]) torch.Size([6])\n",
      "Dilations: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) torch.Size([13])\n",
      "Total padding: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(504, tensor(18))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_params = {\n",
    "    \"kernels\": [8, 6, 4, 3, 2],\n",
    "    \"channels\": [2]*5\n",
    "}\n",
    "\n",
    "smaller_model = TestNet3(**smaller_params)\n",
    "\n",
    "sum(p.numel() for p in smaller_model.parameters() if p.requires_grad), smaller_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 1]) torch.Size([7])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12, 14]) torch.Size([7])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2, 2]) torch.Size([7])\n",
      "Dilations: tensor([1, 2, 3, 4, 2, 1, 1]) torch.Size([7])\n",
      "Total padding: 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, tensor(52))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_params = {\n",
    "    \"kernels\": [5]*6,\n",
    "    \"channels\": [2]*6,\n",
    "    \"dilations\": [1, 2, 3, 4, 2, 1]\n",
    "}\n",
    "\n",
    "small_model = TestNet3(**small_params)\n",
    "\n",
    "sum(p.numel() for p in small_model.parameters() if p.requires_grad), small_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 1]) torch.Size([8])\n",
      "Input channels: tensor([ 2,  6, 10, 13, 16, 18, 20, 22]) torch.Size([8])\n",
      "Channels: tensor([4, 4, 3, 3, 2, 2, 2, 2]) torch.Size([8])\n",
      "Dilations: tensor([1, 2, 3, 4, 3, 2, 1, 1]) torch.Size([8])\n",
      "Total padding: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2222, tensor(64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated2_params = {\n",
    "    \"kernels\": [5]*7,\n",
    "    \"channels\": [4, 4, 3, 3, 2, 2, 2],\n",
    "    \"dilations\": [1, 2, 3, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "dilated2_model = TestNet3(**dilated2_params)\n",
    "\n",
    "sum(p.numel() for p in dilated2_model.parameters() if p.requires_grad), dilated2_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 7, 7, 7, 7, 6, 1]) torch.Size([9])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 18, 20, 22, 24, 26]) torch.Size([9])\n",
      "Channels: tensor([4, 4, 4, 4, 2, 2, 2, 2, 2]) torch.Size([9])\n",
      "Dilations: tensor([ 1,  4,  6, 10, 10,  6,  4,  1,  1]) torch.Size([9])\n",
      "Pads: tensor([ 6, 24, 36, 60, 60, 36, 24,  5,  0]) torch.Size([9])\n",
      "Total padding: 251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4204, 251)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated3_params = {\n",
    "    \"kernels\": [7]*7+[6],\n",
    "    \"channels\": [4, 4, 4, 4, 2, 2, 2, 2],\n",
    "    \"dilations\": [1, 4, 6, 10, 10, 6, 4, 1]\n",
    "}\n",
    "\n",
    "dilated3_model = TestNet3(**dilated3_params)\n",
    "\n",
    "sum(p.numel() for p in dilated3_model.parameters() if p.requires_grad), dilated3_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TestNet3().cuda()\n",
    "# model = smaller_model.cuda()\n",
    "# model = small_model.cuda()\n",
    "# model = dilated2_model.cuda()\n",
    "model = dilated3_model.cuda()\n",
    "unpad = model.pad_total + 1\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "losses = []\n",
    "losses_verbose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2280881d7d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\autograd\\graph.py:690: UserWarning: Error detected in ConvolutionBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_18556\\2404095085.py\", line 16, in <module>\n",
      "    outputs = model(input_tensor)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_18556\\1278572423.py\", line 55, in forward\n",
      "    x = conv(x)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 310, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 306, in _conv_forward\n",
      "    return F.conv1d(input, weight, bias, self.stride,\n",
      " (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:118.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1024, 26, 3843]], which is output 0 of AsStridedBackward0, is at version 10; expected version 9 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mhuber_loss(outputs, target_tensor)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\autograd\\graph.py:690\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1024, 26, 3843]], which is output 0 of AsStridedBackward0, is at version 10; expected version 9 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0.00001)\n",
    "\n",
    "for epoch in range(n_epochs):  # number of epochs\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in ds_full_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.cuda()\n",
    "        input_tensor = batch[:, :-1, :].mT\n",
    "        target_tensor = batch[:, unpad:, :].mT\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.huber_loss(outputs, target_tensor)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_verbose.append(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(2, 8, kernel_size=(5,), stride=(1,))\n",
       "    (1): Conv1d(6, 8, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (2): Conv1d(10, 6, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (3): Conv1d(13, 6, kernel_size=(5,), stride=(1,), dilation=(4,))\n",
       "    (4): Conv1d(16, 4, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (5): Conv1d(18, 4, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (6): Conv1d(20, 4, kernel_size=(5,), stride=(1,))\n",
       "    (7): Conv1d(22, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "# torch.save(model.state_dict(), \"model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TestNet3(\n",
       "   (convs): ModuleList(\n",
       "     (0): Conv1d(2, 8, kernel_size=(5,), stride=(1,))\n",
       "     (1): Conv1d(6, 8, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "     (2): Conv1d(10, 6, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "     (3): Conv1d(13, 6, kernel_size=(5,), stride=(1,), dilation=(4,))\n",
       "     (4): Conv1d(16, 4, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "     (5): Conv1d(18, 4, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "     (6): Conv1d(20, 4, kernel_size=(5,), stride=(1,))\n",
       "     (7): Conv1d(22, 4, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       " ),\n",
       " 64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"dilated2_model.pth\")\n",
    "model = TestNet3(**dilated2_params)\n",
    "model.load_state_dict(torch.load(\"dilated2_model.pth\"))\n",
    "model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TestNet3(\n",
       "   (convs): ModuleList(\n",
       "     (0): Conv1d(2, 16, kernel_size=(5,), stride=(1,))\n",
       "     (1): Conv1d(10, 16, kernel_size=(5,), stride=(1,))\n",
       "     (2): Conv1d(18, 16, kernel_size=(5,), stride=(1,))\n",
       "     (3): Conv1d(26, 16, kernel_size=(5,), stride=(1,))\n",
       "     (4): Conv1d(34, 8, kernel_size=(5,), stride=(1,))\n",
       "     (5): Conv1d(38, 8, kernel_size=(5,), stride=(1,))\n",
       "     (6): Conv1d(42, 8, kernel_size=(5,), stride=(1,))\n",
       "     (7): Conv1d(46, 8, kernel_size=(5,), stride=(1,))\n",
       "     (8): Conv1d(50, 4, kernel_size=(5,), stride=(1,))\n",
       "     (9): Conv1d(52, 4, kernel_size=(5,), stride=(1,))\n",
       "     (10): Conv1d(54, 4, kernel_size=(5,), stride=(1,))\n",
       "     (11): Conv1d(56, 4, kernel_size=(5,), stride=(1,))\n",
       "     (12): Conv1d(58, 4, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       " ),\n",
       " 48)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TestNet3()\n",
    "model.load_state_dict(torch.load(\"model1.pth\"))\n",
    "model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1185, -0.1185, -0.1229, -0.1314,  1.0971],\n",
       "          [ 0.1132,  0.1132,  0.1163,  0.1011,  0.0000]]],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " torch.Size([1, 2, 65]),\n",
       " torch.Size([1, 2, 5]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, model.pad_total + 1, 2)\n",
    "x[:, -2, :] = torch.tensor([-0.05, 0.05])\n",
    "x[:, -1, :] = torch.tensor([-0.1, 0.1])\n",
    "x = x.mT\n",
    "\n",
    "model.ar_len = 5\n",
    "res = model(x)\n",
    "res, x.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "x = x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6 ms ± 209 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  original_name=TestNet3\n",
       "  (convs): ModuleList(\n",
       "    original_name=ModuleList\n",
       "    (0): Conv1d(original_name=Conv1d)\n",
       "    (1): Conv1d(original_name=Conv1d)\n",
       "    (2): Conv1d(original_name=Conv1d)\n",
       "    (3): Conv1d(original_name=Conv1d)\n",
       "    (4): Conv1d(original_name=Conv1d)\n",
       "    (5): Conv1d(original_name=Conv1d)\n",
       "    (6): Conv1d(original_name=Conv1d)\n",
       "    (7): Conv1d(original_name=Conv1d)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.trace(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"dilated2_ar5steps.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregressive_call(x):\n",
    "    res = x\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        res = torch.cat([res[:,1:,:], model(res)[:,-1:,:]], dim=1)\n",
    "    return res[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(autoregressive_call, x, \"dilated2_ar.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1185,  0.1132],\n",
       "         [-0.1234,  0.1060],\n",
       "         [-0.1334,  0.1007],\n",
       "         [-0.1505,  0.1039],\n",
       "         [-0.1711,  0.1115]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoregressive_call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.export(model, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"model1.onnx\")#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.rand(4, 49, 2), \"model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.dynamo_export(model, x, export_options=torch.onnx.ExportOptions(dynamic_shapes=True)).save(\"model3.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
