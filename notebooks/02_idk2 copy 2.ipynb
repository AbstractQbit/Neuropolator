{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from replay_loading import enum_replay_folder, files_to_strokes, sample_stroke\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:16<00:00, 17.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1940603"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_fns = list(itertools.islice(enum_replay_folder(\"H:/osu!/Data/r/\"), 300))\n",
    "strokes_subset = list(files_to_strokes(tqdm(replay_fns), min_length=50))\n",
    "sum((len(s[0]) for s in strokes_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_replays = list(enum_replay_folder(\"H:/osu!/Data/r/\"))\n",
    "# all_strokes = list(files_to_strokes(tqdm(all_replays), min_length=50))\n",
    "# pickle.dump(all_strokes, open(\"all_strokes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = pickle.load(open(\"all_strokes.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, strokes, transforms=None):\n",
    "        self.strokes = strokes\n",
    "        self.transforms = transforms\n",
    "        self.wrand_sampler = WeightedRandomSampler([len(s[0]) for s in strokes], len(strokes), replacement=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strokes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.strokes[idx]\n",
    "        \n",
    "        # Apply the transformations if any\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                sample = transform(sample)\n",
    "            return sample\n",
    "        else:\n",
    "            return sample[1]\n",
    "\n",
    "\n",
    "class StrokeResample:\n",
    "    def __init__(self, rate_range=(30, 250), max_length=2048):\n",
    "        self.rate_range = rate_range\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        timings, positions = sample\n",
    "        rate = np.random.uniform(*self.rate_range)\n",
    "        offset = np.random.uniform(0, 1/rate)\n",
    "        return sample_stroke(timings, positions, rate, offset, max_length=self.max_length)\n",
    "\n",
    "\n",
    "class StrokeDiff:\n",
    "    def __call__(self, sample):\n",
    "        return np.diff(sample, axis=0)\n",
    "\n",
    "\n",
    "class ScaleRotateFlip:\n",
    "    def __init__(self, scale_range=(0.5, 1.5)):\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scale = random.uniform(*self.scale_range)\n",
    "        sample = sample * scale\n",
    "        angle = random.uniform(-np.pi, np.pi)\n",
    "        flip = random.choice([1, -1])\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(angle), -flip * np.sin(angle)],\n",
    "            [flip * np.sin(angle), np.cos(angle)]])\n",
    "        sample = sample @ rotation_matrix\n",
    "        return sample\n",
    "\n",
    "\n",
    "class StrokeToTensor:\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample).float()\n",
    "\n",
    "\n",
    "def collate_pad_beginning_zeroes(batch):\n",
    "    max_len = max([len(stroke) for stroke in batch])\n",
    "    padded_batch = [F.pad(stroke, (0, 0, max_len - len(stroke), 0)) for stroke in batch]\n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    StrokeResample(max_length=4096),\n",
    "    StrokeDiff(),\n",
    "    ScaleRotateFlip(),\n",
    "    StrokeToTensor(),\n",
    "]\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "ds_small = StrokeDataset(strokes_subset, transforms=transforms)\n",
    "ds_small_loader = DataLoader(ds_small, batch_size=batch_size, sampler=ds_small.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)\n",
    "\n",
    "ds_full = StrokeDataset(all_strokes, transforms=transforms)\n",
    "ds_full_loader = DataLoader(ds_full, batch_size=batch_size, sampler=ds_full.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15468"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestNet3(nn.Module):\n",
    "    def __init__(\n",
    "        self, kernels=[5] * 12, channels=[8] * 4 + [4] * 4 + [2] * 4, dilations=[1] * 12\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernels = torch.tensor(kernels + [1])\n",
    "        self.channels = torch.tensor(channels + [2])\n",
    "        self.in_channels = torch.tensor([2] + channels).cumsum(dim=0)[1:]\n",
    "        self.dilations = torch.tensor(dilations + [1])\n",
    "        self.pads = [\n",
    "            (kernel - 1) * dilation\n",
    "            for kernel, dilation in zip(self.kernels, self.dilations)\n",
    "        ]\n",
    "        self.pad_total = sum(self.pads)\n",
    "        self.ar_len = None\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.in_channels[i],\n",
    "                    out_channels=self.channels[i] * 2,\n",
    "                    kernel_size=self.kernels[i],\n",
    "                    dilation=self.dilations[i],\n",
    "                )\n",
    "                for i in range(len(self.kernels))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input is (batch, seq_len, 2)\n",
    "        x = x.mT  # (batch, 2, seq_len)\n",
    "        seq_len = x.shape[-1]\n",
    "        if self.ar_len is None:\n",
    "            acts = torch.empty(\n",
    "                len(self.convs) + 1, x.shape[0], 2, seq_len, device=x.device\n",
    "            )\n",
    "            acts[0] = x\n",
    "            curr_window = x.shape[-1]\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                x = acts[i, ..., -curr_window:]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=1)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[i + 1, ..., -curr_window:] = x\n",
    "            return acts[-1, ..., self.pad_total :].mT\n",
    "        else:\n",
    "            acts = torch.empty(\n",
    "                len(self.convs) + 1,\n",
    "                x.shape[0],\n",
    "                2,\n",
    "                seq_len + self.ar_len,\n",
    "                device=x.device,\n",
    "            )\n",
    "            acts[0, ..., : -self.ar_len] = x[..., : -self.ar_len]\n",
    "            # first pass\n",
    "            curr_window = x.shape[-1]\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                x = acts[i, ..., -curr_window : -self.ar_len]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=1)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[i + 1, ..., -curr_window : -self.ar_len] = x\n",
    "            # later autoregressive passes\n",
    "            for ar_step in range(1, self.ar_len):\n",
    "                acts[0, :, :2, ar_step - self.ar_len] = acts[\n",
    "                    -1, :, :2, ar_step - self.ar_len - 1\n",
    "                ]\n",
    "                for i, conv in enumerate(self.convs):\n",
    "                    x = acts[\n",
    "                        i,\n",
    "                        ...,\n",
    "                        ar_step - self.ar_len - self.pads[i] : ar_step - self.ar_len,\n",
    "                    ]\n",
    "                    x = conv(x)\n",
    "                    x = F.glu(x, dim=1)\n",
    "                    acts[i + 1, ..., ar_step - self.ar_len] = x\n",
    "            return acts[-1, ..., -self.ar_len :].mT\n",
    "\n",
    "\n",
    "sum(p.numel() for p in TestNet3().parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(2, 4, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12).reshape(3,4,1).mT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1518, 0.7039, 0.9079, 0.4819, 0.7187])\n",
      "tensor([0.1397, 0.2576, 0.0632, 0.7932, 0.5475])\n",
      "tensor([0.0231, 0.4255, 0.3238, 0.5744, 0.6584])\n",
      "tensor([0.5648, 0.4304, 0.2299, 0.6200, 0.9840])\n",
      "tensor([0.2865, 0.1193, 0.1234, 0.4334, 0.6601])\n"
     ]
    }
   ],
   "source": [
    "for i in torch.rand(5, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 18)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_params = {\n",
    "    \"kernels\": [8, 6, 4, 3, 2],\n",
    "    \"channels\": [2]*5\n",
    "}\n",
    "\n",
    "smaller_model = TestNet3(**smaller_params)\n",
    "\n",
    "sum(p.numel() for p in smaller_model.parameters() if p.requires_grad), smaller_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 52)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_params = {\n",
    "    \"kernels\": [5]*6,\n",
    "    \"channels\": [2]*6,\n",
    "    \"dilations\": [1, 2, 3, 4, 2, 1]\n",
    "}\n",
    "\n",
    "small_model = TestNet3(**small_params)\n",
    "\n",
    "sum(p.numel() for p in small_model.parameters() if p.requires_grad), small_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222, 64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated2_params = {\n",
    "    \"kernels\": [5]*7,\n",
    "    \"channels\": [4, 4, 3, 3, 2, 2, 2],\n",
    "    \"dilations\": [1, 2, 3, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "dilated2_model = TestNet3(**dilated2_params)\n",
    "\n",
    "sum(p.numel() for p in dilated2_model.parameters() if p.requires_grad), dilated2_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12, 16, 8, 4, 0]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.pads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TestNet3().cuda()\n",
    "# model = smaller_model.cuda()\n",
    "# model = small_model.cuda()\n",
    "model = dilated2_model.cuda()\n",
    "unpad = model.pad_total + 1\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.002)\n",
    "\n",
    "losses = []\n",
    "losses_verbose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5229712479735074, LR: 0.002\n",
      "Epoch 2, Loss: 0.3821570545298868, LR: 0.0019782568627301367\n",
      "Epoch 3, Loss: 0.3689375013521273, LR: 0.001913977730354388\n",
      "Epoch 4, Loss: 0.36065788968513, LR: 0.0018099719094030729\n",
      "Epoch 5, Loss: 0.35650813021616307, LR: 0.001670784953327064\n",
      "Epoch 6, Loss: 0.3537160140466472, LR: 0.0015025000000000001\n",
      "Epoch 7, Loss: 0.3478739497051936, LR: 0.001312471909403073\n",
      "Epoch 8, Loss: 0.35018712132488755, LR: 0.0011090058209513155\n",
      "Epoch 9, Loss: 0.34653664955265445, LR: 0.0009009941790486852\n",
      "Epoch 10, Loss: 0.34713985821972154, LR: 0.0006975280905969276\n",
      "Epoch 11, Loss: 0.3446148657091132, LR: 0.0005075000000000004\n",
      "Epoch 12, Loss: 0.3462069177464263, LR: 0.0003392150466729365\n",
      "Epoch 13, Loss: 0.3435532592202975, LR: 0.0002000280905969274\n",
      "Epoch 14, Loss: 0.3437256664718123, LR: 9.602226964561204e-05\n",
      "Epoch 15, Loss: 0.34169955517603384, LR: 3.174313726986335e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0.00001)\n",
    "\n",
    "for epoch in range(n_epochs):  # number of epochs\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in ds_full_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch[:, :-1, :])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.huber_loss(outputs, batch[:, unpad:, :])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_verbose.append(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(2, 8, kernel_size=(5,), stride=(1,))\n",
       "    (1): Conv1d(6, 8, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (2): Conv1d(10, 6, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (3): Conv1d(13, 6, kernel_size=(5,), stride=(1,), dilation=(4,))\n",
       "    (4): Conv1d(16, 4, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (5): Conv1d(18, 4, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (6): Conv1d(20, 4, kernel_size=(5,), stride=(1,))\n",
       "    (7): Conv1d(22, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "# torch.save(model.state_dict(), \"model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"dilated2_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(2, 16, kernel_size=(5,), stride=(1,))\n",
       "    (1): Conv1d(10, 16, kernel_size=(5,), stride=(1,))\n",
       "    (2): Conv1d(18, 16, kernel_size=(5,), stride=(1,))\n",
       "    (3): Conv1d(26, 16, kernel_size=(5,), stride=(1,))\n",
       "    (4): Conv1d(34, 8, kernel_size=(5,), stride=(1,))\n",
       "    (5): Conv1d(38, 8, kernel_size=(5,), stride=(1,))\n",
       "    (6): Conv1d(42, 8, kernel_size=(5,), stride=(1,))\n",
       "    (7): Conv1d(46, 8, kernel_size=(5,), stride=(1,))\n",
       "    (8): Conv1d(50, 4, kernel_size=(5,), stride=(1,))\n",
       "    (9): Conv1d(52, 4, kernel_size=(5,), stride=(1,))\n",
       "    (10): Conv1d(54, 4, kernel_size=(5,), stride=(1,))\n",
       "    (11): Conv1d(56, 4, kernel_size=(5,), stride=(1,))\n",
       "    (12): Conv1d(58, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TestNet3()\n",
    "model.load_state_dict(torch.load(\"model1.pth\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2) must match the existing size (8) at non-singleton dimension 1.  Target sizes: [1, 2, 45].  Tensor sizes: [8, 45]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.05\u001b[39m])\n\u001b[0;32m      3\u001b[0m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 50\u001b[0m, in \u001b[0;36mTestNet3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mglu(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     49\u001b[0m         curr_window \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpads[i]\n\u001b[1;32m---> 50\u001b[0m         \u001b[43macts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mcurr_window\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_total:]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (8) at non-singleton dimension 1.  Target sizes: [1, 2, 45].  Tensor sizes: [8, 45]"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1, model.pad_total + 1, 2)\n",
    "x[:, -2, :] = torch.tensor([-0.05, 0.05])\n",
    "x[:, -1, :] = torch.tensor([-0.1, 0.1])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "x = x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21 ms ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"dilated2_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregressive_call(x):\n",
    "    res = x\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        res = torch.cat([res[:,1:,:], model(res)[:,-1:,:]], dim=1)\n",
    "    return res[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoregressive_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilated2_ar.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[0;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\utils.py:1590\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m   1585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule)):\n\u001b[0;32m   1586\u001b[0m     module_typenames_to_export_as_functions \u001b[38;5;241m=\u001b[39m _setup_trace_module_map(\n\u001b[0;32m   1587\u001b[0m         model, export_modules_as_functions\n\u001b[0;32m   1588\u001b[0m     )\n\u001b[1;32m-> 1590\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexporter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_keep_init_as_ip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_decide_keep_init_as_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1595\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_add_node_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_decide_add_node_names\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_node_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\utils.py:179\u001b[0m, in \u001b[0;36mexporter_context\u001b[1;34m(model, mode, verbose)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexporter_context\u001b[39m(model, mode: _C_onnx\u001b[38;5;241m.\u001b[39mTrainingMode, verbose: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mselect_model_mode_for_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_apex_o2_state_dict_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapex_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup_onnx_logging\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlog_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagnostics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_export_diagnostic_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdiagnostic_ctx\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapex_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagnostic_ctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\utils.py:140\u001b[0m, in \u001b[0;36mdisable_apex_o2_state_dict_hook\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction):\n\u001b[0;32m    139\u001b[0m     model_hooks \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m():\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, hook \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(hook)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO2StateDictHook\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'modules'"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(autoregressive_call, x, \"dilated2_ar.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1185,  0.1132],\n",
       "         [-0.1234,  0.1060],\n",
       "         [-0.1334,  0.1007],\n",
       "         [-0.1505,  0.1039],\n",
       "         [-0.1711,  0.1115]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoregressive_call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Windows not yet supported for torch.compile",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\export\\__init__.py:191\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(f, args, kwargs, constraints, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     constraints \u001b[38;5;241m=\u001b[39m _process_dynamic_shapes(f, args, kwargs, dynamic_shapes)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\export\\exported_program.py:78\u001b[0m, in \u001b[0;36m_disable_prexisiting_fake_mode.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m maybe_disable_fake_tensor_mode():\n\u001b[1;32m---> 78\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\export\\_trace.py:588\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(f, args, kwargs, constraints, strict, preserve_module_call_signature, pre_dispatch)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m out_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExportedProgram(\n\u001b[0;32m    571\u001b[0m         root\u001b[38;5;241m=\u001b[39mep_non_strict\u001b[38;5;241m.\u001b[39mgm,\n\u001b[0;32m    572\u001b[0m         graph\u001b[38;5;241m=\u001b[39mep_non_strict\u001b[38;5;241m.\u001b[39mgm\u001b[38;5;241m.\u001b[39mgraph,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m         tensor_constants\u001b[38;5;241m=\u001b[39mep_non_strict\u001b[38;5;241m.\u001b[39mtensor_constants,\n\u001b[0;32m    586\u001b[0m     )\n\u001b[1;32m--> 588\u001b[0m gm_torch_level \u001b[38;5;241m=\u001b[39m \u001b[43m_export_to_torch_ir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_fqn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't need to restore because we will do it later\u001b[39;49;00m\n\u001b[0;32m    595\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m params_buffers \u001b[38;5;241m=\u001b[39m _get_params_buffers(gm_torch_level)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# We detect the fake_mode by looking at gm_torch_level's placeholders, this is the fake_mode created in dynamo.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\export\\_trace.py:267\u001b[0m, in \u001b[0;36m_export_to_torch_ir\u001b[1;34m(f, args, kwargs, constraints, preserve_module_call_signature, disable_constraint_solver, restore_fqn)\u001b[0m\n\u001b[0;32m    265\u001b[0m     module_call_specs: Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, pytree\u001b[38;5;241m.\u001b[39mTreeSpec]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _wrap_submodules(f, preserve_module_call_signature, module_call_specs):\n\u001b[1;32m--> 267\u001b[0m         gm_torch_level, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43massume_static_by_default\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtracing_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msymbolic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_constraint_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_constraint_solver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ConstraintViolationError, ValueRangeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserError(UserErrorType\u001b[38;5;241m.\u001b[39mCONSTRAINT_VIOLATION, \u001b[38;5;28mstr\u001b[39m(e))  \u001b[38;5;66;03m# noqa: TRY200\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1161\u001b[0m, in \u001b[0;36mexport.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m f \u001b[38;5;241m=\u001b[39m _f\n\u001b[0;32m   1160\u001b[0m assume_static_by_default \u001b[38;5;241m=\u001b[39m _assume_static_by_default\n\u001b[1;32m-> 1161\u001b[0m \u001b[43mcheck_if_dynamo_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._dynamo.export\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decomposition_table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:625\u001b[0m, in \u001b[0;36mcheck_if_dynamo_supported\u001b[1;34m()\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_if_dynamo_supported\u001b[39m():\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 625\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows not yet supported for torch.compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m    627\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3.12+ not yet supported for torch.compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Windows not yet supported for torch.compile"
     ]
    }
   ],
   "source": [
    "torch.export.export(model, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"model1.onnx\")#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.rand(4, 49, 2), \"model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OnnxExporterError",
     "evalue": "Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter.py:1432\u001b[0m, in \u001b[0;36mdynamo_export\u001b[1;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_export_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter.py:1174\u001b[0m, in \u001b[0;36mExporter.export\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdiagnostic_context:\n\u001b[1;32m-> 1174\u001b[0m     graph_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx_tracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_fx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;66;03m# TODO: Defer `import onnxscript` out of `import torch` path\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/103764\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\_internal\\fx\\dynamo_graph_extractor.py:213\u001b[0m, in \u001b[0;36mDynamoExport.generate_fx\u001b[1;34m(self, options, model, model_args, model_kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fake_mode:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     graph_module, graph_guard \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracing_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfx_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m graph_guard  \u001b[38;5;66;03m# Unused\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1161\u001b[0m, in \u001b[0;36mexport.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1160\u001b[0m assume_static_by_default \u001b[38;5;241m=\u001b[39m _assume_static_by_default\n\u001b[1;32m-> 1161\u001b[0m \u001b[43mcheck_if_dynamo_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._dynamo.export\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:625\u001b[0m, in \u001b[0;36mcheck_if_dynamo_supported\u001b[1;34m()\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows not yet supported for torch.compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Windows not yet supported for torch.compile",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamo_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExportOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel3.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter.py:1443\u001b[0m, in \u001b[0;36mdynamo_export\u001b[1;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[0;32m   1435\u001b[0m resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context\u001b[38;5;241m.\u001b[39mdump(sarif_report_path)\n\u001b[0;32m   1436\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1437\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to export the model to ONNX. Generating SARIF report at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msarif_report_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSARIF is a standard format for the output of static analysis tools. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease report a bug on PyTorch Github: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_PYTORCH_GITHUB_ISSUES_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m )\n\u001b[1;32m-> 1443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OnnxExporterError(\n\u001b[0;32m   1444\u001b[0m     ONNXProgram\u001b[38;5;241m.\u001b[39m_from_failure(e, resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context),\n\u001b[0;32m   1445\u001b[0m     message,\n\u001b[0;32m   1446\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOnnxExporterError\u001b[0m: Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues"
     ]
    }
   ],
   "source": [
    "torch.onnx.dynamo_export(model, x, export_options=torch.onnx.ExportOptions(dynamic_shapes=True)).save(\"model3.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
