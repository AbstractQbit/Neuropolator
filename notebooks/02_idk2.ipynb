{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from replay_loading import enum_replay_folder, files_to_strokes, sample_stroke\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:17<00:00, 17.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1930021"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_fns = list(itertools.islice(enum_replay_folder(\"H:/osu!/Data/r/\"), 300))\n",
    "strokes_subset = list(files_to_strokes(tqdm(replay_fns), min_length=50))\n",
    "sum((len(s[0]) for s in strokes_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_replays = list(enum_replay_folder(\"H:/osu!/Data/r/\"))\n",
    "# all_strokes = list(files_to_strokes(tqdm(all_replays), min_length=50))\n",
    "# pickle.dump(all_strokes, open(\"all_strokes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = pickle.load(open(\"all_strokes.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, strokes, transforms=None):\n",
    "        self.strokes = strokes\n",
    "        self.transforms = transforms\n",
    "        self.wrand_sampler = WeightedRandomSampler([len(s[0]) for s in strokes], len(strokes), replacement=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strokes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.strokes[idx]\n",
    "        \n",
    "        # Apply the transformations if any\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                sample = transform(sample)\n",
    "            return sample\n",
    "        else:\n",
    "            return sample[1]\n",
    "\n",
    "\n",
    "class StrokeResample:\n",
    "    def __init__(self, rate_range=(30, 250), max_length=2048):\n",
    "        self.rate_range = rate_range\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        timings, positions = sample\n",
    "        rate = np.random.uniform(*self.rate_range)\n",
    "        offset = np.random.uniform(0, 1/rate)\n",
    "        return sample_stroke(timings, positions, rate, offset, max_length=self.max_length)\n",
    "\n",
    "\n",
    "class StrokeDiff:\n",
    "    def __call__(self, sample):\n",
    "        return np.diff(sample, axis=0)\n",
    "\n",
    "\n",
    "class ScaleRotateFlip:\n",
    "    def __init__(self, scale_range=(0.5, 1.5)):\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scale = random.uniform(*self.scale_range)\n",
    "        sample = sample * scale\n",
    "        angle = random.uniform(-np.pi, np.pi)\n",
    "        flip = random.choice([1, -1])\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(angle), -flip * np.sin(angle)],\n",
    "            [flip * np.sin(angle), np.cos(angle)]])\n",
    "        sample = sample @ rotation_matrix\n",
    "        return sample\n",
    "\n",
    "\n",
    "class StrokeToTensor:\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample).float()\n",
    "\n",
    "\n",
    "def collate_pad_beginning_zeroes(batch):\n",
    "    max_len = max([len(stroke) for stroke in batch])\n",
    "    padded_batch = [F.pad(stroke, (0, 0, max_len - len(stroke), 0)) for stroke in batch]\n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    StrokeResample(max_length=4096),\n",
    "    StrokeDiff(),\n",
    "    ScaleRotateFlip(),\n",
    "    StrokeToTensor(),\n",
    "]\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "ds_small = StrokeDataset(strokes_subset, transforms=transforms)\n",
    "ds_small_loader = DataLoader(ds_small, batch_size=batch_size, sampler=ds_small.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)\n",
    "\n",
    "ds_full = StrokeDataset(all_strokes, transforms=transforms)\n",
    "ds_full_loader = DataLoader(ds_full, batch_size=batch_size, sampler=ds_full.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1])\n",
      "Input channels: tensor([ 2, 10, 18, 26, 34, 38, 42, 46, 50, 52, 54, 56, 58])\n",
      "Channels: tensor([8, 8, 8, 8, 4, 4, 4, 4, 2, 2, 2, 2, 2])\n",
      "Dilations: None\n",
      "Pads: tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0])\n",
      "Total padding: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15468"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class TestNet3(torch.jit.ScriptModule):\n",
    "    def __init__(\n",
    "        self, kernels=[5] * 12, channels=[8] * 4 + [4] * 4 + [2] * 4, dilations=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernels = torch.tensor(kernels + [1])\n",
    "        self.channels = torch.tensor(channels + [2])\n",
    "        self.in_channels = torch.tensor([2] + channels).cumsum(dim=0)\n",
    "        self.total_channels = self.in_channels[-1].item() + 2\n",
    "        self.dilations = torch.tensor(dilations + [1]) if dilations is not None else None\n",
    "        self.pads = (self.kernels - 1) * (self.dilations if self.dilations is not None else 1)\n",
    "        self.pad_total = self.pads.sum().item()\n",
    "        self.pad_max = self.pads.max().item()\n",
    "        self.ar_len = 5\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.in_channels[i].item(),\n",
    "                    out_channels=self.channels[i].item() * 2,\n",
    "                    kernel_size=self.kernels[i].item(),\n",
    "                    dilation=self.dilations[i].item() if self.dilations is not None else 1,\n",
    "                )\n",
    "                for i in range(len(self.kernels))\n",
    "            ]\n",
    "        )\n",
    "        self.n_layers = len(self.convs)\n",
    "\n",
    "        print(f\"Kernels: {self.kernels}\")\n",
    "        print(f\"Input channels: {self.in_channels}\")\n",
    "        print(f\"Channels: {self.channels}\")\n",
    "        print(f\"Dilations: {self.dilations}\")\n",
    "        print(f\"Pads: {self.pads}\")\n",
    "        print(f\"Total padding: {self.pad_total}\")\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        # input is (batch, seq_len, 2)\n",
    "        # x = x.mT  # (batch, 2, seq_len)\n",
    "        curr_window = torch.tensor(x.shape[-1])\n",
    "        acts = [x]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = torch.cat([act[..., -curr_window:] for act in acts], dim=1)\n",
    "            x = conv(x)\n",
    "            x = F.glu(x, dim=1)\n",
    "            curr_window -= self.pads[i]\n",
    "            acts.append(x)\n",
    "        return x\n",
    "\n",
    "    def forward_ar(self, x):\n",
    "        batch_size = torch.tensor(x.shape[0])\n",
    "        seq_len = torch.tensor(x.shape[-1])\n",
    "        acts = torch.empty(\n",
    "            batch_size,\n",
    "            self.total_channels,\n",
    "            seq_len + self.ar_len - 1,\n",
    "            device=x.device,\n",
    "        )\n",
    "        acts[..., :2, :seq_len] = x\n",
    "        # first pass\n",
    "        curr_window = seq_len.clone()\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            channel_start = self.in_channels[i]\n",
    "            channel_end = channel_start + self.channels[i]\n",
    "            x = acts[..., :channel_start, seq_len - curr_window : seq_len]\n",
    "            x = conv(x)\n",
    "            x = F.glu(x, dim=-2)\n",
    "            curr_window -= self.pads[i]\n",
    "            acts[\n",
    "                ...,\n",
    "                channel_start:channel_end,\n",
    "                seq_len - curr_window : seq_len,\n",
    "            ] = x\n",
    "        # later autoregressive passes\n",
    "        for ar_step in range(1, self.ar_len):\n",
    "            step_col = seq_len + ar_step - 1\n",
    "            acts[..., :2, step_col] = acts[..., -2:, step_col - 1]\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                channel_start = self.in_channels[i]\n",
    "                channel_end = channel_start + self.channels[i]\n",
    "                x = acts[\n",
    "                    ...,\n",
    "                    :channel_start,\n",
    "                    step_col - self.pads[i] - 1 : step_col,\n",
    "                ]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=-2)\n",
    "                acts[\n",
    "                    ...,\n",
    "                    channel_start:channel_end,\n",
    "                    step_col : step_col + 1,\n",
    "                ] = x\n",
    "        return acts[..., -2:, -self.ar_len :]  # .mT\n",
    "    \n",
    "    # @torch.jit.script_method\n",
    "    def forward_ar_jit(self, x):\n",
    "        batch_size = torch.tensor(x.shape[0])\n",
    "        seq_len = torch.tensor(x.shape[-1])\n",
    "        acts = [x]\n",
    "        # first pass\n",
    "        curr_window = seq_len.clone()\n",
    "        for i, conv1 in enumerate(self.convs):\n",
    "            x = torch.cat([act[..., -curr_window:] for act in acts], dim=1)\n",
    "            x = conv1(x)\n",
    "            x = F.glu(x, dim=1)\n",
    "            curr_window -= self.pads[i]\n",
    "            acts.append(x)\n",
    "        # print([act[..., -self.pad_max:].shape for act in acts])\n",
    "        # acts = torch.cat([act[..., -self.pad_max:] for act in acts], dim=1)\n",
    "        res = [acts[:, -2:, -1]]\n",
    "        # later autoregressive passes\n",
    "        for ar_step in range(1, self.ar_len):\n",
    "            # step_col = seq_len + ar_step - 1\n",
    "            step_acts = [res[-1]]\n",
    "            for i, conv2 in enumerate(self.convs):\n",
    "                x = torch.cat([acts[:, :self.in_channels[i], -self.pads[i]:], torch.cat(step_acts, dim=1)], dim=2)\n",
    "                x = conv2(x)\n",
    "                x = F.glu(x, dim=1)\n",
    "                step_acts.append(x)\n",
    "            res.append(step_acts[-1])\n",
    "            acts = torch.cat([acts[..., 1:], torch.cat(step_acts, dim=1)], dim=2)\n",
    "        return torch.stack(res, dim=-1)\n",
    "\n",
    "\n",
    "sum(p.numel() for p in TestNet3().parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8), tensor(-1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor(8)\n",
    "x2 = x1.clone()\n",
    "x2-= 9\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)[-2:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([8, 6, 4, 3, 2, 1])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2])\n",
      "Dilations: None\n",
      "Pads: tensor([7, 5, 3, 2, 1, 0])\n",
      "Total padding: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(504, 18)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_params = {\n",
    "    \"kernels\": [8, 6, 4, 3, 2],\n",
    "    \"channels\": [2]*5\n",
    "}\n",
    "\n",
    "smaller_model = TestNet3(**smaller_params)\n",
    "\n",
    "sum(p.numel() for p in smaller_model.parameters() if p.requires_grad), smaller_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 1])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12, 14])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2, 2])\n",
      "Dilations: tensor([1, 2, 3, 4, 2, 1, 1])\n",
      "Pads: tensor([ 4,  8, 12, 16,  8,  4,  0])\n",
      "Total padding: 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 52)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_params = {\n",
    "    \"kernels\": [5]*6,\n",
    "    \"channels\": [2]*6,\n",
    "    \"dilations\": [1, 2, 3, 4, 2, 1]\n",
    "}\n",
    "\n",
    "small_model = TestNet3(**small_params)\n",
    "\n",
    "sum(p.numel() for p in small_model.parameters() if p.requires_grad), small_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 13, 16, 18, 20, 22])\n",
      "Channels: tensor([4, 4, 3, 3, 2, 2, 2, 2])\n",
      "Dilations: tensor([1, 2, 3, 4, 3, 2, 1, 1])\n",
      "Pads: tensor([ 4,  8, 12, 16, 12,  8,  4,  0])\n",
      "Total padding: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2222, 64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated2_params = {\n",
    "    \"kernels\": [5]*7,\n",
    "    \"channels\": [4, 4, 3, 3, 2, 2, 2],\n",
    "    \"dilations\": [1, 2, 3, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "dilated2_model = TestNet3(**dilated2_params)\n",
    "\n",
    "sum(p.numel() for p in dilated2_model.parameters() if p.requires_grad), dilated2_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 7, 7, 7, 7, 6, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 18, 20, 22, 24, 26])\n",
      "Channels: tensor([4, 4, 4, 4, 2, 2, 2, 2, 2])\n",
      "Dilations: tensor([ 1,  4,  6, 10, 10,  6,  4,  1,  1])\n",
      "Pads: tensor([ 6, 24, 36, 60, 60, 36, 24,  5,  0])\n",
      "Total padding: 251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4204, 251)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated3_params = {\n",
    "    \"kernels\": [7]*7+[6],\n",
    "    \"channels\": [4, 4, 4, 4, 2, 2, 2, 2],\n",
    "    \"dilations\": [1, 4, 6, 10, 10, 6, 4, 1]\n",
    "}\n",
    "\n",
    "dilated3_model = TestNet3(**dilated3_params)\n",
    "\n",
    "sum(p.numel() for p in dilated3_model.parameters() if p.requires_grad), dilated3_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 5, 5, 5, 3, 3, 3, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 17, 20, 23, 24, 25, 26])\n",
      "Channels: tensor([4, 4, 4, 3, 3, 3, 1, 1, 1, 2])\n",
      "Dilations: tensor([ 1,  2,  8, 12, 16, 12,  8,  2,  1,  1])\n",
      "Pads: tensor([ 6, 12, 48, 48, 64, 48, 16,  4,  2,  0])\n",
      "Total padding: 248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3126, 248)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dilated4_params = {\n",
    "#     \"kernels\": [3, 3, 4, 4, 5, 5, 6, 6],\n",
    "#     \"channels\": [4, 4, 3, 3, 2, 2, 1, 1],\n",
    "#     \"dilations\": [1, 1, 2, 4, 6, 8, 10, 12]\n",
    "# }\n",
    "dilated4_params = {\n",
    "    \"kernels\": [7, 7, 7, 5, 5, 5, 3, 3, 3],\n",
    "    \"channels\": [4, 4, 4, 3, 3, 3, 1, 1, 1],\n",
    "    \"dilations\": [1, 2, 8, 12, 16, 12, 8, 2, 1],\n",
    "}\n",
    "\n",
    "dilated4_model = TestNet3(**dilated4_params)\n",
    "\n",
    "# init all biases to 0\n",
    "for m in dilated4_model.modules():\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "(\n",
    "    sum(p.numel() for p in dilated4_model.parameters() if p.requires_grad),\n",
    "    dilated4_model.pad_total,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dilated4_model.cuda()\n",
    "unpad = model.pad_total + 1\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005)\n",
    "\n",
    "losses = []\n",
    "losses_verbose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5033286178493064, LR: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.38214694569099983, LR: 0.004969282409784869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.3659466698289462, LR: 0.004877886008156408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3564784242410094, LR: 0.004728061277849978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:52<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.35366976410830947, LR: 0.004523497400965494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:52<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.3505887469472406, LR: 0.004269231419060436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:52<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.3470866908765819, LR: 0.00397152420446972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.34482313549681887, LR: 0.0036377062968501695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.3434695118366311, LR: 0.0032759974009654944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:48<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.3455778790391199, LR: 0.0028953039902753766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:49<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.3413932738510985, LR: 0.0025050000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.3412224732033194, LR: 0.002114696009724625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.34027855472477603, LR: 0.0017340025990345066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.3399965980825903, LR: 0.001372293703149831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.34245839238711145, LR: 0.00103847579553028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.3406832905392669, LR: 0.0007407685809395642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:51<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.3395968001999267, LR: 0.00048650259903450645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.34061274898650984, LR: 0.0002819387221500224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.34042032001769706, LR: 0.00013211399184359196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [01:50<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.3396178048495288, LR: 4.0717590215131546e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0.00001)\n",
    "\n",
    "for m in dilated4_model.modules():\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        m.bias.requires_grad = False\n",
    "\n",
    "for epoch in range(n_epochs):  # number of epochs\n",
    "    epoch_losses = []\n",
    "\n",
    "    if epoch == 1:\n",
    "        for m in dilated4_model.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                m.bias.requires_grad = True\n",
    "\n",
    "    for batch in tqdm(ds_full_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.cuda()\n",
    "        input_tensor = batch[:, :-1, :].mT\n",
    "        target_tensor = batch[:, unpad:, :].mT\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.huber_loss(outputs, target_tensor)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_verbose.append(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  (convs): RecursiveScriptModule(\n",
       "    original_name=ModuleList\n",
       "    (0): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (1): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (2): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (3): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (4): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (5): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (6): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (7): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (8): RecursiveScriptModule(original_name=Conv1d)\n",
       "    (9): RecursiveScriptModule(original_name=Conv1d)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "# torch.save(model.state_dict(), \"model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TestNet3()\n",
    "# model.load_state_dict(torch.load(\"model1.pth\"))\n",
    "# model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([7, 7, 7, 5, 5, 5, 3, 3, 3, 1])\n",
      "Input channels: tensor([ 2,  6, 10, 14, 17, 20, 23, 24, 25, 26])\n",
      "Channels: tensor([4, 4, 4, 3, 3, 3, 1, 1, 1, 2])\n",
      "Dilations: tensor([ 1,  2,  8, 12, 16, 12,  8,  2,  1,  1])\n",
      "Pads: tensor([ 6, 12, 48, 48, 64, 48, 16,  4,  2,  0])\n",
      "Total padding: 248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TestNet3(\n",
       "   (convs): RecursiveScriptModule(\n",
       "     original_name=ModuleList\n",
       "     (0): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (1): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (2): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (3): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (4): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (5): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (6): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (7): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (8): RecursiveScriptModule(original_name=Conv1d)\n",
       "     (9): RecursiveScriptModule(original_name=Conv1d)\n",
       "   )\n",
       " ),\n",
       " 248)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"dilated4_model.pth\")\n",
    "model = TestNet3(**dilated4_params)\n",
    "model.load_state_dict(torch.load(\"dilated4_model.pth\"))\n",
    "model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.9452, 1.9452, 2.0111, 1.5037, 2.0517],\n",
       "          [1.9527, 1.9527, 2.0368, 3.2496, 2.8725]]]),\n",
       " torch.Size([1, 2, 249]),\n",
       " torch.Size([1, 2, 5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, model.pad_total + 1, 2)\n",
    "x[:, -1, :] = torch.tensor([1, 1])\n",
    "# x[:, -2, :] = torch.tensor([-0.05, 0.05])\n",
    "# x[:, -1, :] = torch.tensor([-0.1, 0.1])\n",
    "x = x.mT\n",
    "\n",
    "model.ar_len = 5\n",
    "with torch.no_grad():\n",
    "    res = model.forward_ar(x)\n",
    "res, x.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 2, 64]), torch.Size([1, 4, 64]), torch.Size([1, 4, 64]), torch.Size([1, 4, 64]), torch.Size([1, 3, 64]), torch.Size([1, 3, 64]), torch.Size([1, 3, 23]), torch.Size([1, 1, 7]), torch.Size([1, 1, 3]), torch.Size([1, 1, 1]), torch.Size([1, 2, 1])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 64 but got size 23 for tensor number 6 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_ar_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m res, x\u001b[38;5;241m.\u001b[39mshape, res\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[28], line 110\u001b[0m, in \u001b[0;36mTestNet3.forward_ar_jit\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    108\u001b[0m     acts\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m([act[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_max:]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m acts])\n\u001b[1;32m--> 110\u001b[0m acts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mact\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_max\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mact\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m res \u001b[38;5;241m=\u001b[39m [acts[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# later autoregressive passes\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 23 for tensor number 6 in the list."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    res = model.forward_ar_jit(x)\n",
    "res, x.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "x = x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.71 ms ± 185 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit with torch.no_grad(): model.forward_ar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:43: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  batch_size = torch.tensor(x.shape[0])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_size = torch.tensor(x.shape[0])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:44: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  seq_len = torch.tensor(x.shape[-1])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_len = torch.tensor(x.shape[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99 ms ± 177 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "optimized_model = torch.jit.trace(model, x)\n",
    "%timeit with torch.no_grad(): optimized_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:43: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  batch_size = torch.tensor(x.shape[0])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_size = torch.tensor(x.shape[0])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:44: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  seq_len = torch.tensor(x.shape[-1])\n",
      "C:\\Users\\Abstract\\AppData\\Local\\Temp\\ipykernel_3740\\2265697626.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_len = torch.tensor(x.shape[-1])\n",
      "c:\\Users\\Abstract\\mambaforge\\envs\\deepenv\\Lib\\site-packages\\torch\\onnx\\utils.py:631: UserWarning: ONNX Preprocess - Removing mutation from node aten::copy_ on block input: '0'. This changes graph semantics. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\passes\\onnx\\remove_inplace_ops_for_onnx.cpp:355.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, x, \"dilated4_ar5steps.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregressive_call(x):\n",
    "    res = x\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        res = torch.cat([res[:,1:,:], model(res)[:,-1:,:]], dim=1)\n",
    "    return res[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(autoregressive_call, x, \"dilated2_ar.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1185,  0.1132],\n",
       "         [-0.1234,  0.1060],\n",
       "         [-0.1334,  0.1007],\n",
       "         [-0.1505,  0.1039],\n",
       "         [-0.1711,  0.1115]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoregressive_call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.export(model, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"model1.onnx\")#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.rand(4, 49, 2), \"model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.dynamo_export(model, x, export_options=torch.onnx.ExportOptions(dynamic_shapes=True)).save(\"model3.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
