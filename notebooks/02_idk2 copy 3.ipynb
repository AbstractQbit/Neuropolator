{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from replay_loading import enum_replay_folder, files_to_strokes, sample_stroke\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:16<00:00, 17.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1940603"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_fns = list(itertools.islice(enum_replay_folder(\"H:/osu!/Data/r/\"), 300))\n",
    "strokes_subset = list(files_to_strokes(tqdm(replay_fns), min_length=50))\n",
    "sum((len(s[0]) for s in strokes_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_replays = list(enum_replay_folder(\"H:/osu!/Data/r/\"))\n",
    "# all_strokes = list(files_to_strokes(tqdm(all_replays), min_length=50))\n",
    "# pickle.dump(all_strokes, open(\"all_strokes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = pickle.load(open(\"all_strokes.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeDataset(Dataset):\n",
    "    def __init__(self, strokes, transforms=None):\n",
    "        self.strokes = strokes\n",
    "        self.transforms = transforms\n",
    "        self.wrand_sampler = WeightedRandomSampler([len(s[0]) for s in strokes], len(strokes), replacement=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strokes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.strokes[idx]\n",
    "        \n",
    "        # Apply the transformations if any\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                sample = transform(sample)\n",
    "            return sample\n",
    "        else:\n",
    "            return sample[1]\n",
    "\n",
    "\n",
    "class StrokeResample:\n",
    "    def __init__(self, rate_range=(30, 250), max_length=2048):\n",
    "        self.rate_range = rate_range\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        timings, positions = sample\n",
    "        rate = np.random.uniform(*self.rate_range)\n",
    "        offset = np.random.uniform(0, 1/rate)\n",
    "        return sample_stroke(timings, positions, rate, offset, max_length=self.max_length)\n",
    "\n",
    "\n",
    "class StrokeDiff:\n",
    "    def __call__(self, sample):\n",
    "        return np.diff(sample, axis=0)\n",
    "\n",
    "\n",
    "class ScaleRotateFlip:\n",
    "    def __init__(self, scale_range=(0.5, 1.5)):\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scale = random.uniform(*self.scale_range)\n",
    "        sample = sample * scale\n",
    "        angle = random.uniform(-np.pi, np.pi)\n",
    "        flip = random.choice([1, -1])\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(angle), -flip * np.sin(angle)],\n",
    "            [flip * np.sin(angle), np.cos(angle)]])\n",
    "        sample = sample @ rotation_matrix\n",
    "        return sample\n",
    "\n",
    "\n",
    "class StrokeToTensor:\n",
    "    def __call__(self, sample):\n",
    "        return torch.from_numpy(sample).float()\n",
    "\n",
    "\n",
    "def collate_pad_beginning_zeroes(batch):\n",
    "    max_len = max([len(stroke) for stroke in batch])\n",
    "    padded_batch = [F.pad(stroke, (0, 0, max_len - len(stroke), 0)) for stroke in batch]\n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    StrokeResample(max_length=4096),\n",
    "    StrokeDiff(),\n",
    "    ScaleRotateFlip(),\n",
    "    StrokeToTensor(),\n",
    "]\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "ds_small = StrokeDataset(strokes_subset, transforms=transforms)\n",
    "ds_small_loader = DataLoader(ds_small, batch_size=batch_size, sampler=ds_small.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)\n",
    "\n",
    "ds_full = StrokeDataset(all_strokes, transforms=transforms)\n",
    "ds_full_loader = DataLoader(ds_full, batch_size=batch_size, sampler=ds_full.wrand_sampler, collate_fn=collate_pad_beginning_zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15468"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestNet3(nn.Module):\n",
    "    def __init__(\n",
    "        self, kernels=[5] * 12, channels=[8] * 4 + [4] * 4 + [2] * 4, dilations=[1] * 12\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernels = torch.tensor(kernels + [1])\n",
    "        self.channels = torch.tensor(channels + [2])\n",
    "        self.in_channels = torch.tensor([2] + channels).cumsum(dim=0)\n",
    "        self.total_channels = self.in_channels[-1].item() + 2\n",
    "        self.dilations = torch.tensor(dilations + [1])\n",
    "        self.pads = [\n",
    "            (kernel - 1) * dilation\n",
    "            for kernel, dilation in zip(self.kernels, self.dilations)\n",
    "        ]\n",
    "        self.pad_total = sum(self.pads).item()\n",
    "        self.ar_len = None\n",
    "\n",
    "        # print(f\"Kernels: {self.kernels} {self.kernels.shape}\")\n",
    "        # print(f\"Input channels: {self.in_channels} {self.in_channels.shape}\")\n",
    "        # print(f\"Channels: {self.channels} {self.channels.shape}\")\n",
    "        # print(f\"Dilations: {self.dilations} {self.dilations.shape}\")\n",
    "        # print(f\"Pads: {self.pads} {self.pads.shape}\")\n",
    "        # print(f\"Total padding: {self.pad_total}\")\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=self.in_channels[i].item(),\n",
    "                    out_channels=self.channels[i].item() * 2,\n",
    "                    kernel_size=self.kernels[i].item(),\n",
    "                    dilation=self.dilations[i].item(),\n",
    "                )\n",
    "                for i in range(len(self.kernels))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input is (batch, seq_len, 2)\n",
    "        # x = x.mT  # (batch, 2, seq_len)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[-1]\n",
    "        if self.ar_len is None:\n",
    "            acts = torch.empty(\n",
    "                batch_size, self.total_channels, seq_len, device=x.device\n",
    "            )\n",
    "            acts[..., :2, :] = x\n",
    "            curr_window = seq_len\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                channel_start = self.in_channels[i].item()\n",
    "                channel_end = channel_start + self.channels[i].item()\n",
    "                x = acts[..., :channel_start, -curr_window:]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=-2)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[\n",
    "                    ...,\n",
    "                    channel_start:channel_end,\n",
    "                    -curr_window:,\n",
    "                ] = x\n",
    "            return acts[..., -2:, -curr_window:]  # .mT\n",
    "        else:\n",
    "            acts = torch.empty(\n",
    "                batch_size,\n",
    "                self.total_channels,\n",
    "                seq_len + self.ar_len - 1,\n",
    "                device=x.device,\n",
    "            )\n",
    "            acts[..., :2, :seq_len] = x\n",
    "            # first pass\n",
    "            curr_window = seq_len\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                channel_start = self.in_channels[i]\n",
    "                channel_end = channel_start + self.channels[i]\n",
    "                x = acts[..., :channel_start, seq_len - curr_window : seq_len]\n",
    "                x = conv(x)\n",
    "                x = F.glu(x, dim=-2)\n",
    "                curr_window -= self.pads[i]\n",
    "                acts[\n",
    "                    ...,\n",
    "                    channel_start:channel_end,\n",
    "                    seq_len - curr_window : seq_len,\n",
    "                ] = x\n",
    "            # later autoregressive passes\n",
    "            for ar_step in range(1, self.ar_len):\n",
    "                step_col = ar_step - self.ar_len\n",
    "                acts[..., :2, step_col] = acts[..., -2:, step_col - 1]\n",
    "                for i, conv in enumerate(self.convs):\n",
    "                    channel_start = self.in_channels[i]\n",
    "                    channel_end = channel_start + self.channels[i]\n",
    "                    x = acts[\n",
    "                        ...,\n",
    "                        :channel_start,\n",
    "                        step_col - self.pads[i] - 1 : step_col,\n",
    "                    ]\n",
    "                    x = conv(x)\n",
    "                    x = F.glu(x, dim=-2)\n",
    "                    acts[\n",
    "                        ...,\n",
    "                        channel_start:channel_end,\n",
    "                        step_col : step_col + 1,\n",
    "                    ] = x\n",
    "            return acts[..., -2:, -self.ar_len :]  # .mT\n",
    "\n",
    "\n",
    "sum(p.numel() for p in TestNet3().parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2276, 0.7897, 0.7854, 0.4141, 0.3337])\n",
      "tensor([0.2103, 0.5353, 0.6915, 0.1386, 0.8969])\n",
      "tensor([0.3024, 0.9456, 0.0404, 0.8617, 0.9429])\n",
      "tensor([0.3049, 0.6746, 0.9541, 0.7280, 0.6335])\n",
      "tensor([0.2845, 0.6857, 0.4670, 0.2040, 0.1037])\n"
     ]
    }
   ],
   "source": [
    "for i in torch.rand(5, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([8, 6, 4, 3, 2, 1]) torch.Size([6])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12]) torch.Size([6])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2]) torch.Size([6])\n",
      "Dilations: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) torch.Size([13])\n",
      "Total padding: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(504, tensor(18))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_params = {\n",
    "    \"kernels\": [8, 6, 4, 3, 2],\n",
    "    \"channels\": [2]*5\n",
    "}\n",
    "\n",
    "smaller_model = TestNet3(**smaller_params)\n",
    "\n",
    "sum(p.numel() for p in smaller_model.parameters() if p.requires_grad), smaller_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 1]) torch.Size([7])\n",
      "Input channels: tensor([ 2,  4,  6,  8, 10, 12, 14]) torch.Size([7])\n",
      "Channels: tensor([2, 2, 2, 2, 2, 2, 2]) torch.Size([7])\n",
      "Dilations: tensor([1, 2, 3, 4, 2, 1, 1]) torch.Size([7])\n",
      "Total padding: 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, tensor(52))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_params = {\n",
    "    \"kernels\": [5]*6,\n",
    "    \"channels\": [2]*6,\n",
    "    \"dilations\": [1, 2, 3, 4, 2, 1]\n",
    "}\n",
    "\n",
    "small_model = TestNet3(**small_params)\n",
    "\n",
    "sum(p.numel() for p in small_model.parameters() if p.requires_grad), small_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: tensor([5, 5, 5, 5, 5, 5, 5, 1]) torch.Size([8])\n",
      "Input channels: tensor([ 2,  6, 10, 13, 16, 18, 20, 22]) torch.Size([8])\n",
      "Channels: tensor([4, 4, 3, 3, 2, 2, 2, 2]) torch.Size([8])\n",
      "Dilations: tensor([1, 2, 3, 4, 3, 2, 1, 1]) torch.Size([8])\n",
      "Total padding: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2222, tensor(64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated2_params = {\n",
    "    \"kernels\": [5]*7,\n",
    "    \"channels\": [4, 4, 3, 3, 2, 2, 2],\n",
    "    \"dilations\": [1, 2, 3, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "dilated2_model = TestNet3(**dilated2_params)\n",
    "\n",
    "sum(p.numel() for p in dilated2_model.parameters() if p.requires_grad), dilated2_model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12, 16, 8, 4, 0]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.pads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TestNet3().cuda()\n",
    "# model = smaller_model.cuda()\n",
    "# model = small_model.cuda()\n",
    "model = dilated2_model.cuda()\n",
    "unpad = model.pad_total + 1\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.002)\n",
    "\n",
    "losses = []\n",
    "losses_verbose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5229712479735074, LR: 0.002\n",
      "Epoch 2, Loss: 0.3821570545298868, LR: 0.0019782568627301367\n",
      "Epoch 3, Loss: 0.3689375013521273, LR: 0.001913977730354388\n",
      "Epoch 4, Loss: 0.36065788968513, LR: 0.0018099719094030729\n",
      "Epoch 5, Loss: 0.35650813021616307, LR: 0.001670784953327064\n",
      "Epoch 6, Loss: 0.3537160140466472, LR: 0.0015025000000000001\n",
      "Epoch 7, Loss: 0.3478739497051936, LR: 0.001312471909403073\n",
      "Epoch 8, Loss: 0.35018712132488755, LR: 0.0011090058209513155\n",
      "Epoch 9, Loss: 0.34653664955265445, LR: 0.0009009941790486852\n",
      "Epoch 10, Loss: 0.34713985821972154, LR: 0.0006975280905969276\n",
      "Epoch 11, Loss: 0.3446148657091132, LR: 0.0005075000000000004\n",
      "Epoch 12, Loss: 0.3462069177464263, LR: 0.0003392150466729365\n",
      "Epoch 13, Loss: 0.3435532592202975, LR: 0.0002000280905969274\n",
      "Epoch 14, Loss: 0.3437256664718123, LR: 9.602226964561204e-05\n",
      "Epoch 15, Loss: 0.34169955517603384, LR: 3.174313726986335e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0.00001)\n",
    "\n",
    "for epoch in range(n_epochs):  # number of epochs\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in ds_full_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch[:, :-1, :])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.huber_loss(outputs, batch[:, unpad:, :])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    losses.append(epoch_loss)\n",
    "    losses_verbose.append(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(2, 8, kernel_size=(5,), stride=(1,))\n",
       "    (1): Conv1d(6, 8, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (2): Conv1d(10, 6, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (3): Conv1d(13, 6, kernel_size=(5,), stride=(1,), dilation=(4,))\n",
       "    (4): Conv1d(16, 4, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "    (5): Conv1d(18, 4, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "    (6): Conv1d(20, 4, kernel_size=(5,), stride=(1,))\n",
       "    (7): Conv1d(22, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "# torch.save(model.state_dict(), \"model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TestNet3(\n",
       "   (convs): ModuleList(\n",
       "     (0): Conv1d(2, 8, kernel_size=(5,), stride=(1,))\n",
       "     (1): Conv1d(6, 8, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "     (2): Conv1d(10, 6, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "     (3): Conv1d(13, 6, kernel_size=(5,), stride=(1,), dilation=(4,))\n",
       "     (4): Conv1d(16, 4, kernel_size=(5,), stride=(1,), dilation=(3,))\n",
       "     (5): Conv1d(18, 4, kernel_size=(5,), stride=(1,), dilation=(2,))\n",
       "     (6): Conv1d(20, 4, kernel_size=(5,), stride=(1,))\n",
       "     (7): Conv1d(22, 4, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       " ),\n",
       " 64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"dilated2_model.pth\")\n",
    "model = TestNet3(**dilated2_params)\n",
    "model.load_state_dict(torch.load(\"dilated2_model.pth\"))\n",
    "model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TestNet3(\n",
       "   (convs): ModuleList(\n",
       "     (0): Conv1d(2, 16, kernel_size=(5,), stride=(1,))\n",
       "     (1): Conv1d(10, 16, kernel_size=(5,), stride=(1,))\n",
       "     (2): Conv1d(18, 16, kernel_size=(5,), stride=(1,))\n",
       "     (3): Conv1d(26, 16, kernel_size=(5,), stride=(1,))\n",
       "     (4): Conv1d(34, 8, kernel_size=(5,), stride=(1,))\n",
       "     (5): Conv1d(38, 8, kernel_size=(5,), stride=(1,))\n",
       "     (6): Conv1d(42, 8, kernel_size=(5,), stride=(1,))\n",
       "     (7): Conv1d(46, 8, kernel_size=(5,), stride=(1,))\n",
       "     (8): Conv1d(50, 4, kernel_size=(5,), stride=(1,))\n",
       "     (9): Conv1d(52, 4, kernel_size=(5,), stride=(1,))\n",
       "     (10): Conv1d(54, 4, kernel_size=(5,), stride=(1,))\n",
       "     (11): Conv1d(56, 4, kernel_size=(5,), stride=(1,))\n",
       "     (12): Conv1d(58, 4, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       " ),\n",
       " 48)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TestNet3()\n",
    "model.load_state_dict(torch.load(\"model1.pth\"))\n",
    "model, model.pad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1185, -0.1185, -0.1229, -0.1314,  1.0971],\n",
       "          [ 0.1132,  0.1132,  0.1163,  0.1011,  0.0000]]],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " torch.Size([1, 2, 65]),\n",
       " torch.Size([1, 2, 5]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, model.pad_total + 1, 2)\n",
    "x[:, -2, :] = torch.tensor([-0.05, 0.05])\n",
    "x[:, -1, :] = torch.tensor([-0.1, 0.1])\n",
    "x = x.mT\n",
    "\n",
    "model.ar_len = 5\n",
    "res = model(x)\n",
    "res, x.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "x = x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6 ms ± 209 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNet3(\n",
       "  original_name=TestNet3\n",
       "  (convs): ModuleList(\n",
       "    original_name=ModuleList\n",
       "    (0): Conv1d(original_name=Conv1d)\n",
       "    (1): Conv1d(original_name=Conv1d)\n",
       "    (2): Conv1d(original_name=Conv1d)\n",
       "    (3): Conv1d(original_name=Conv1d)\n",
       "    (4): Conv1d(original_name=Conv1d)\n",
       "    (5): Conv1d(original_name=Conv1d)\n",
       "    (6): Conv1d(original_name=Conv1d)\n",
       "    (7): Conv1d(original_name=Conv1d)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.trace(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"dilated2_ar5steps.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregressive_call(x):\n",
    "    res = x\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        res = torch.cat([res[:,1:,:], model(res)[:,-1:,:]], dim=1)\n",
    "    return res[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(autoregressive_call, x, \"dilated2_ar.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1185,  0.1132],\n",
       "         [-0.1234,  0.1060],\n",
       "         [-0.1334,  0.1007],\n",
       "         [-0.1505,  0.1039],\n",
       "         [-0.1711,  0.1115]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoregressive_call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.export(model, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x, \"model1.onnx\")#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, torch.rand(4, 49, 2), \"model2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.dynamo_export(model, x, export_options=torch.onnx.ExportOptions(dynamic_shapes=True)).save(\"model3.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
